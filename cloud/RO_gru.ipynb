{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:10:06 Time:  0:10:06\n"
     ]
    }
   ],
   "source": [
    "%run train_data_generate_script.py -k train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Mode Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. A GRU model that output the basic mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:1.091\n",
      "########## 20 loss:0.947\n",
      "########## 30 loss:0.582\n",
      "########## 40 loss:0.494\n",
      "########## 50 loss:0.495\n",
      "########## 60 loss:0.488\n",
      "########## 70 loss:0.485\n",
      "########## 80 loss:0.484\n",
      "########## 90 loss:0.484\n",
      "########## 100 loss:0.482\n",
      "########## 110 loss:0.482\n",
      "########## 120 loss:0.480\n",
      "########## 130 loss:0.484\n",
      "########## 140 loss:0.480\n",
      "########## 150 loss:0.481\n",
      "########## 160 loss:0.481\n",
      "########## 170 loss:0.477\n",
      "########## 180 loss:0.459\n",
      "########## 190 loss:0.278\n",
      "########## 200 loss:0.118\n",
      "########## 210 loss:0.083\n",
      "########## 220 loss:0.061\n",
      "########## 230 loss:0.058\n",
      "########## 240 loss:0.055\n",
      "########## 250 loss:0.051\n",
      "########## 260 loss:0.053\n",
      "########## 270 loss:0.050\n",
      "########## 280 loss:0.050\n",
      "########## 290 loss:0.051\n",
      "########## 300 loss:0.052\n",
      "########## 310 loss:0.049\n",
      "########## 320 loss:0.048\n",
      "########## 330 loss:0.051\n",
      "########## 340 loss:0.047\n",
      "########## 350 loss:0.045\n",
      "########## 360 loss:0.038\n",
      "########## 370 loss:0.037\n",
      "########## 380 loss:0.042\n",
      "########## 390 loss:0.034\n",
      "########## 400 loss:0.172\n",
      "########## 410 loss:0.104\n",
      "########## 420 loss:0.069\n",
      "########## 430 loss:0.059\n",
      "########## 440 loss:0.056\n",
      "########## 450 loss:0.052\n",
      "########## 460 loss:0.050\n",
      "########## 470 loss:0.047\n",
      "########## 480 loss:0.047\n",
      "########## 490 loss:0.043\n",
      "########## 500 loss:0.043\n",
      "########## 510 loss:0.041\n",
      "########## 520 loss:0.039\n",
      "########## 530 loss:0.036\n",
      "########## 540 loss:0.034\n",
      "########## 550 loss:0.034\n",
      "########## 560 loss:0.031\n",
      "########## 570 loss:0.030\n",
      "########## 580 loss:0.028\n",
      "########## 590 loss:0.028\n",
      "########## 600 loss:0.030\n",
      "########## 610 loss:0.026\n",
      "########## 620 loss:0.027\n",
      "########## 630 loss:0.026\n",
      "########## 640 loss:0.027\n",
      "########## 650 loss:0.027\n",
      "########## 660 loss:0.026\n",
      "########## 670 loss:0.028\n",
      "########## 680 loss:0.025\n",
      "########## 690 loss:0.027\n",
      "########## 700 loss:0.025\n",
      "########## 710 loss:0.026\n",
      "########## 720 loss:0.026\n",
      "########## 730 loss:0.026\n",
      "########## 740 loss:0.027\n",
      "########## 750 loss:0.026\n",
      "########## 760 loss:0.025\n",
      "########## 770 loss:0.025\n",
      "########## 780 loss:0.049\n",
      "########## 790 loss:0.039\n",
      "########## 800 loss:0.033\n",
      "########## 810 loss:0.030\n",
      "########## 820 loss:0.027\n",
      "########## 830 loss:0.026\n",
      "########## 840 loss:0.026\n",
      "########## 850 loss:0.024\n",
      "########## 860 loss:0.025\n",
      "########## 870 loss:0.025\n",
      "########## 880 loss:0.024\n",
      "########## 890 loss:0.024\n",
      "########## 900 loss:0.025\n",
      "########## 910 loss:0.025\n",
      "########## 920 loss:0.025\n",
      "########## 930 loss:0.024\n",
      "########## 940 loss:0.025\n",
      "########## 950 loss:0.025\n",
      "########## 960 loss:0.024\n",
      "########## 970 loss:0.023\n",
      "########## 980 loss:0.022\n",
      "########## 990 loss:0.023\n",
      "########## 1000 loss:0.024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t detector -n gru -o gru_mode_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. A CNN-GRU model that output the basic mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:0.994\n",
      "########## 20 loss:0.659\n",
      "########## 30 loss:0.522\n",
      "########## 40 loss:0.512\n",
      "########## 50 loss:0.502\n",
      "########## 60 loss:0.501\n",
      "########## 70 loss:0.494\n",
      "########## 80 loss:0.467\n",
      "########## 90 loss:0.500\n",
      "########## 100 loss:0.397\n",
      "########## 110 loss:0.332\n",
      "########## 120 loss:0.116\n",
      "########## 130 loss:0.093\n",
      "########## 140 loss:0.073\n",
      "########## 150 loss:0.063\n",
      "########## 160 loss:0.057\n",
      "########## 170 loss:0.055\n",
      "########## 180 loss:0.056\n",
      "########## 190 loss:0.050\n",
      "########## 200 loss:0.600\n",
      "########## 210 loss:0.442\n",
      "########## 220 loss:0.165\n",
      "########## 230 loss:0.096\n",
      "########## 240 loss:0.080\n",
      "########## 250 loss:0.071\n",
      "########## 260 loss:0.069\n",
      "########## 270 loss:0.063\n",
      "########## 280 loss:0.057\n",
      "########## 290 loss:0.051\n",
      "########## 300 loss:0.062\n",
      "########## 310 loss:0.065\n",
      "########## 320 loss:0.058\n",
      "########## 330 loss:0.057\n",
      "########## 340 loss:0.051\n",
      "########## 350 loss:0.049\n",
      "########## 360 loss:0.045\n",
      "########## 370 loss:0.040\n",
      "########## 380 loss:0.038\n",
      "########## 390 loss:0.036\n",
      "########## 400 loss:0.045\n",
      "########## 410 loss:0.042\n",
      "########## 420 loss:0.037\n",
      "########## 430 loss:0.033\n",
      "########## 440 loss:0.036\n",
      "########## 450 loss:0.037\n",
      "########## 460 loss:0.033\n",
      "########## 470 loss:0.028\n",
      "########## 480 loss:0.027\n",
      "########## 490 loss:0.027\n",
      "########## 500 loss:0.026\n",
      "########## 510 loss:0.027\n",
      "########## 520 loss:0.042\n",
      "########## 530 loss:0.044\n",
      "########## 540 loss:0.037\n",
      "########## 550 loss:0.031\n",
      "########## 560 loss:0.027\n",
      "########## 570 loss:0.026\n",
      "########## 580 loss:0.025\n",
      "########## 590 loss:0.023\n",
      "########## 600 loss:0.022\n",
      "########## 610 loss:0.023\n",
      "########## 620 loss:0.021\n",
      "########## 630 loss:0.021\n",
      "########## 640 loss:0.021\n",
      "########## 650 loss:0.034\n",
      "########## 660 loss:0.038\n",
      "########## 670 loss:0.029\n",
      "########## 680 loss:0.026\n",
      "########## 690 loss:0.025\n",
      "########## 700 loss:0.023\n",
      "########## 710 loss:0.023\n",
      "########## 720 loss:0.022\n",
      "########## 730 loss:0.020\n",
      "########## 740 loss:0.019\n",
      "########## 750 loss:0.018\n",
      "########## 760 loss:0.018\n",
      "########## 770 loss:0.018\n",
      "########## 780 loss:0.018\n",
      "########## 790 loss:0.020\n",
      "########## 800 loss:0.022\n",
      "########## 810 loss:0.018\n",
      "########## 820 loss:0.018\n",
      "########## 830 loss:0.017\n",
      "########## 840 loss:0.017\n",
      "########## 850 loss:0.016\n",
      "########## 860 loss:0.022\n",
      "########## 870 loss:0.019\n",
      "########## 880 loss:0.018\n",
      "########## 890 loss:0.017\n",
      "########## 900 loss:0.016\n",
      "########## 910 loss:0.015\n",
      "########## 920 loss:0.015\n",
      "########## 930 loss:0.016\n",
      "########## 940 loss:0.016\n",
      "########## 950 loss:0.018\n",
      "########## 960 loss:0.016\n",
      "########## 970 loss:0.015\n",
      "########## 980 loss:0.014\n",
      "########## 990 loss:0.014\n",
      "########## 1000 loss:0.014\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t detector -n cnn_gru -o cnn_gru_mode_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Isolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Obs based parameter fault isolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:1.288\n",
      "########## 20 loss:1.046\n",
      "########## 30 loss:0.965\n",
      "########## 40 loss:0.950\n",
      "########## 50 loss:0.954\n",
      "########## 60 loss:0.948\n",
      "########## 70 loss:0.948\n",
      "########## 80 loss:0.946\n",
      "########## 90 loss:0.927\n",
      "########## 100 loss:0.902\n",
      "########## 110 loss:0.852\n",
      "########## 120 loss:0.811\n",
      "########## 130 loss:0.812\n",
      "########## 140 loss:0.756\n",
      "########## 150 loss:0.750\n",
      "########## 160 loss:0.747\n",
      "########## 170 loss:0.610\n",
      "########## 180 loss:0.646\n",
      "########## 190 loss:0.625\n",
      "########## 200 loss:0.578\n",
      "########## 210 loss:0.529\n",
      "########## 220 loss:0.549\n",
      "########## 230 loss:0.642\n",
      "########## 240 loss:0.568\n",
      "########## 250 loss:0.618\n",
      "########## 260 loss:0.547\n",
      "########## 270 loss:0.603\n",
      "########## 280 loss:0.522\n",
      "########## 290 loss:0.485\n",
      "########## 300 loss:0.526\n",
      "########## 310 loss:0.480\n",
      "########## 320 loss:0.506\n",
      "########## 330 loss:0.473\n",
      "########## 340 loss:0.533\n",
      "########## 350 loss:0.466\n",
      "########## 360 loss:0.494\n",
      "########## 370 loss:0.507\n",
      "########## 380 loss:0.399\n",
      "########## 390 loss:0.379\n",
      "########## 400 loss:0.376\n",
      "########## 410 loss:0.501\n",
      "########## 420 loss:0.444\n",
      "########## 430 loss:0.401\n",
      "########## 440 loss:0.357\n",
      "########## 450 loss:0.360\n",
      "########## 460 loss:0.320\n",
      "########## 470 loss:0.316\n",
      "########## 480 loss:0.312\n",
      "########## 490 loss:0.578\n",
      "########## 500 loss:0.610\n",
      "########## 510 loss:0.515\n",
      "########## 520 loss:0.489\n",
      "########## 530 loss:0.443\n",
      "########## 540 loss:0.435\n",
      "########## 550 loss:0.507\n",
      "########## 560 loss:0.516\n",
      "########## 570 loss:0.443\n",
      "########## 580 loss:0.414\n",
      "########## 590 loss:0.460\n",
      "########## 600 loss:0.574\n",
      "########## 610 loss:0.546\n",
      "########## 620 loss:0.531\n",
      "########## 630 loss:0.578\n",
      "########## 640 loss:0.711\n",
      "########## 650 loss:0.822\n",
      "########## 660 loss:0.679\n",
      "########## 670 loss:0.647\n",
      "########## 680 loss:0.644\n",
      "########## 690 loss:0.646\n",
      "########## 700 loss:0.641\n",
      "########## 710 loss:0.599\n",
      "########## 720 loss:0.565\n",
      "########## 730 loss:0.494\n",
      "########## 740 loss:0.563\n",
      "########## 750 loss:0.698\n",
      "########## 760 loss:0.656\n",
      "########## 770 loss:0.641\n",
      "########## 780 loss:0.646\n",
      "########## 790 loss:0.630\n",
      "########## 800 loss:0.635\n",
      "########## 810 loss:0.623\n",
      "########## 820 loss:0.635\n",
      "########## 830 loss:0.635\n",
      "########## 840 loss:0.633\n",
      "########## 850 loss:0.624\n",
      "########## 860 loss:0.632\n",
      "########## 870 loss:0.621\n",
      "########## 880 loss:0.629\n",
      "########## 890 loss:0.625\n",
      "########## 900 loss:0.621\n",
      "########## 910 loss:0.628\n",
      "########## 920 loss:0.618\n",
      "########## 930 loss:0.616\n",
      "########## 940 loss:0.627\n",
      "########## 950 loss:0.614\n",
      "########## 960 loss:0.560\n",
      "########## 970 loss:0.547\n",
      "########## 980 loss:0.482\n",
      "########## 990 loss:0.490\n",
      "########## 1000 loss:0.500\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t isolator -n cnn_gru -o cnn_gru_pf_isolator_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Residual based parameter fault isolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:1.321\n",
      "########## 20 loss:0.749\n",
      "########## 30 loss:0.365\n",
      "########## 40 loss:0.141\n",
      "########## 50 loss:0.048\n",
      "########## 60 loss:0.026\n",
      "########## 70 loss:0.022\n",
      "########## 80 loss:0.022\n",
      "########## 90 loss:0.017\n",
      "########## 100 loss:0.015\n",
      "########## 110 loss:0.013\n",
      "########## 120 loss:0.011\n",
      "########## 130 loss:0.011\n",
      "########## 140 loss:0.011\n",
      "########## 150 loss:0.015\n",
      "########## 160 loss:0.013\n",
      "########## 170 loss:0.011\n",
      "########## 180 loss:0.010\n",
      "########## 190 loss:0.010\n",
      "########## 200 loss:0.009\n",
      "########## 210 loss:0.009\n",
      "########## 220 loss:0.009\n",
      "########## 230 loss:0.009\n",
      "########## 240 loss:0.008\n",
      "########## 250 loss:0.009\n",
      "########## 260 loss:0.010\n",
      "########## 270 loss:0.008\n",
      "########## 280 loss:0.008\n",
      "########## 290 loss:0.008\n",
      "########## 300 loss:0.008\n",
      "########## 310 loss:0.008\n",
      "########## 320 loss:0.010\n",
      "########## 330 loss:0.008\n",
      "########## 340 loss:0.008\n",
      "########## 350 loss:0.008\n",
      "########## 360 loss:0.008\n",
      "########## 370 loss:0.008\n",
      "########## 380 loss:0.007\n",
      "########## 390 loss:0.007\n",
      "########## 400 loss:0.007\n",
      "########## 410 loss:0.007\n",
      "########## 420 loss:0.007\n",
      "########## 430 loss:0.007\n",
      "########## 440 loss:0.007\n",
      "########## 450 loss:0.008\n",
      "########## 460 loss:0.013\n",
      "########## 470 loss:0.014\n",
      "########## 480 loss:0.011\n",
      "########## 490 loss:0.009\n",
      "########## 500 loss:0.008\n",
      "########## 510 loss:0.009\n",
      "########## 520 loss:0.030\n",
      "########## 530 loss:0.018\n",
      "########## 540 loss:0.016\n",
      "########## 550 loss:0.013\n",
      "########## 560 loss:0.011\n",
      "########## 570 loss:0.010\n",
      "########## 580 loss:0.010\n",
      "########## 590 loss:0.010\n",
      "########## 600 loss:0.009\n",
      "########## 610 loss:0.008\n",
      "########## 620 loss:0.008\n",
      "########## 630 loss:0.008\n",
      "########## 640 loss:0.007\n",
      "########## 650 loss:0.007\n",
      "########## 660 loss:0.007\n",
      "########## 670 loss:0.007\n",
      "########## 680 loss:0.007\n",
      "########## 690 loss:0.007\n",
      "########## 700 loss:0.007\n",
      "########## 710 loss:0.008\n",
      "########## 720 loss:0.007\n",
      "########## 730 loss:0.007\n",
      "########## 740 loss:0.007\n",
      "########## 750 loss:0.007\n",
      "########## 760 loss:0.006\n",
      "########## 770 loss:0.006\n",
      "########## 780 loss:0.007\n",
      "########## 790 loss:0.007\n",
      "########## 800 loss:0.007\n",
      "########## 810 loss:0.007\n",
      "########## 820 loss:0.007\n",
      "########## 830 loss:0.006\n",
      "########## 840 loss:0.006\n",
      "########## 850 loss:0.006\n",
      "########## 860 loss:0.008\n",
      "########## 870 loss:0.008\n",
      "########## 880 loss:0.007\n",
      "########## 890 loss:0.007\n",
      "########## 900 loss:0.007\n",
      "########## 910 loss:0.006\n",
      "########## 920 loss:0.006\n",
      "########## 930 loss:0.006\n",
      "########## 940 loss:0.007\n",
      "########## 950 loss:0.007\n",
      "########## 960 loss:0.007\n",
      "########## 970 loss:0.007\n",
      "########## 980 loss:0.007\n",
      "########## 990 loss:0.007\n",
      "########## 1000 loss:0.006\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t isolator -n cnn_gru -o cnn_gru_pf_isolator_res -r on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train f_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Obs based f_f Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:14.944\n",
      "########## 20 loss:12.473\n",
      "########## 30 loss:10.970\n",
      "########## 40 loss:7.296\n",
      "########## 50 loss:5.036\n",
      "########## 60 loss:3.826\n",
      "########## 70 loss:3.802\n",
      "########## 80 loss:2.960\n",
      "########## 90 loss:3.052\n",
      "########## 100 loss:2.634\n",
      "########## 110 loss:2.640\n",
      "########## 120 loss:2.440\n",
      "########## 130 loss:2.815\n",
      "########## 140 loss:2.610\n",
      "########## 150 loss:2.923\n",
      "########## 160 loss:2.459\n",
      "########## 170 loss:2.764\n",
      "########## 180 loss:2.489\n",
      "########## 190 loss:2.582\n",
      "########## 200 loss:2.681\n",
      "########## 210 loss:2.264\n",
      "########## 220 loss:2.564\n",
      "########## 230 loss:2.527\n",
      "########## 240 loss:2.460\n",
      "########## 250 loss:2.674\n",
      "########## 260 loss:2.554\n",
      "########## 270 loss:2.612\n",
      "########## 280 loss:2.835\n",
      "########## 290 loss:2.374\n",
      "########## 300 loss:2.473\n",
      "########## 310 loss:2.216\n",
      "########## 320 loss:2.583\n",
      "########## 330 loss:2.034\n",
      "########## 340 loss:1.916\n",
      "########## 350 loss:3.068\n",
      "########## 360 loss:2.426\n",
      "########## 370 loss:2.704\n",
      "########## 380 loss:2.787\n",
      "########## 390 loss:2.712\n",
      "########## 400 loss:5.989\n",
      "########## 410 loss:4.715\n",
      "########## 420 loss:3.318\n",
      "########## 430 loss:2.961\n",
      "########## 440 loss:2.920\n",
      "########## 450 loss:2.702\n",
      "########## 460 loss:2.543\n",
      "########## 470 loss:2.459\n",
      "########## 480 loss:2.543\n",
      "########## 490 loss:2.246\n",
      "########## 500 loss:2.258\n",
      "########## 510 loss:2.109\n",
      "########## 520 loss:2.393\n",
      "########## 530 loss:2.535\n",
      "########## 540 loss:2.199\n",
      "########## 550 loss:2.484\n",
      "########## 560 loss:2.333\n",
      "########## 570 loss:2.297\n",
      "########## 580 loss:2.119\n",
      "########## 590 loss:2.222\n",
      "########## 600 loss:2.094\n",
      "########## 610 loss:2.466\n",
      "########## 620 loss:2.416\n",
      "########## 630 loss:2.073\n",
      "########## 640 loss:2.225\n",
      "########## 650 loss:2.254\n",
      "########## 660 loss:2.219\n",
      "########## 670 loss:2.229\n",
      "########## 680 loss:2.176\n",
      "########## 690 loss:2.235\n",
      "########## 700 loss:2.170\n",
      "########## 710 loss:2.240\n",
      "########## 720 loss:2.180\n",
      "########## 730 loss:2.419\n",
      "########## 740 loss:2.252\n",
      "########## 750 loss:2.037\n",
      "########## 760 loss:2.118\n",
      "########## 770 loss:2.024\n",
      "########## 780 loss:2.187\n",
      "########## 790 loss:2.586\n",
      "########## 800 loss:2.452\n",
      "########## 810 loss:2.374\n",
      "########## 820 loss:2.127\n",
      "########## 830 loss:1.989\n",
      "########## 840 loss:2.105\n",
      "########## 850 loss:2.396\n",
      "########## 860 loss:2.419\n",
      "########## 870 loss:2.306\n",
      "########## 880 loss:2.284\n",
      "########## 890 loss:2.370\n",
      "########## 900 loss:1.987\n",
      "########## 910 loss:2.063\n",
      "########## 920 loss:2.008\n",
      "########## 930 loss:2.071\n",
      "########## 940 loss:2.082\n",
      "########## 950 loss:2.077\n",
      "########## 960 loss:2.177\n",
      "########## 970 loss:2.123\n",
      "########## 980 loss:1.979\n",
      "########## 990 loss:2.056\n",
      "########## 1000 loss:1.928\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t f_f -n cnn_gru -o cnn_gru_f_f_identifier_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Residual based f_f Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:14.022\n",
      "########## 20 loss:1.039\n",
      "########## 30 loss:0.399\n",
      "########## 40 loss:0.236\n",
      "########## 50 loss:0.163\n",
      "########## 60 loss:0.117\n",
      "########## 70 loss:0.100\n",
      "########## 80 loss:0.082\n",
      "########## 90 loss:0.107\n",
      "########## 100 loss:0.119\n",
      "########## 110 loss:0.087\n",
      "########## 120 loss:0.069\n",
      "########## 130 loss:0.062\n",
      "########## 140 loss:0.061\n",
      "########## 150 loss:0.063\n",
      "########## 160 loss:0.060\n",
      "########## 170 loss:0.064\n",
      "########## 180 loss:0.102\n",
      "########## 190 loss:0.144\n",
      "########## 200 loss:0.101\n",
      "########## 210 loss:0.063\n",
      "########## 220 loss:0.070\n",
      "########## 230 loss:0.073\n",
      "########## 240 loss:0.057\n",
      "########## 250 loss:0.069\n",
      "########## 260 loss:0.057\n",
      "########## 270 loss:0.047\n",
      "########## 280 loss:0.047\n",
      "########## 290 loss:0.045\n",
      "########## 300 loss:0.045\n",
      "########## 310 loss:0.037\n",
      "########## 320 loss:0.051\n",
      "########## 330 loss:0.046\n",
      "########## 340 loss:0.040\n",
      "########## 350 loss:0.039\n",
      "########## 360 loss:0.038\n",
      "########## 370 loss:0.069\n",
      "########## 380 loss:0.046\n",
      "########## 390 loss:0.036\n",
      "########## 400 loss:0.035\n",
      "########## 410 loss:0.041\n",
      "########## 420 loss:0.040\n",
      "########## 430 loss:0.099\n",
      "########## 440 loss:0.048\n",
      "########## 450 loss:0.074\n",
      "########## 460 loss:0.054\n",
      "########## 470 loss:0.057\n",
      "########## 480 loss:0.042\n",
      "########## 490 loss:0.034\n",
      "########## 500 loss:0.029\n",
      "########## 510 loss:0.029\n",
      "########## 520 loss:0.028\n",
      "########## 530 loss:0.026\n",
      "########## 540 loss:0.025\n",
      "########## 550 loss:0.026\n",
      "########## 560 loss:0.023\n",
      "########## 570 loss:0.025\n",
      "########## 580 loss:0.026\n",
      "########## 590 loss:0.026\n",
      "########## 600 loss:0.027\n",
      "########## 610 loss:0.026\n",
      "########## 620 loss:0.057\n",
      "########## 630 loss:0.193\n",
      "########## 640 loss:0.063\n",
      "########## 650 loss:0.033\n",
      "########## 660 loss:0.029\n",
      "########## 670 loss:0.028\n",
      "########## 680 loss:0.026\n",
      "########## 690 loss:0.024\n",
      "########## 700 loss:0.024\n",
      "########## 710 loss:0.027\n",
      "########## 720 loss:0.024\n",
      "########## 730 loss:0.023\n",
      "########## 740 loss:0.021\n",
      "########## 750 loss:0.022\n",
      "########## 760 loss:0.022\n",
      "########## 770 loss:0.022\n",
      "########## 780 loss:0.024\n",
      "########## 790 loss:0.030\n",
      "########## 800 loss:0.024\n",
      "########## 810 loss:0.024\n",
      "########## 820 loss:0.058\n",
      "########## 830 loss:0.096\n",
      "########## 840 loss:0.061\n",
      "########## 850 loss:0.061\n",
      "########## 860 loss:0.052\n",
      "########## 870 loss:0.030\n",
      "########## 880 loss:0.033\n",
      "########## 890 loss:0.029\n",
      "########## 900 loss:0.023\n",
      "########## 910 loss:0.021\n",
      "########## 920 loss:0.020\n",
      "########## 930 loss:0.025\n",
      "########## 940 loss:0.022\n",
      "########## 950 loss:0.020\n",
      "########## 960 loss:0.021\n",
      "########## 970 loss:0.019\n",
      "########## 980 loss:0.023\n",
      "########## 990 loss:0.030\n",
      "########## 1000 loss:0.021\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t f_f -n cnn_gru -o cnn_gru_f_f_identifier_res -r on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train f_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Obs based f_r identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:10.530\n",
      "########## 20 loss:7.911\n",
      "########## 30 loss:4.502\n",
      "########## 40 loss:2.138\n",
      "########## 50 loss:1.301\n",
      "########## 60 loss:0.820\n",
      "########## 70 loss:0.580\n",
      "########## 80 loss:0.463\n",
      "########## 90 loss:0.375\n",
      "########## 100 loss:0.313\n",
      "########## 110 loss:0.277\n",
      "########## 120 loss:0.273\n",
      "########## 130 loss:0.244\n",
      "########## 140 loss:0.231\n",
      "########## 150 loss:0.205\n",
      "########## 160 loss:0.252\n",
      "########## 170 loss:0.458\n",
      "########## 180 loss:0.304\n",
      "########## 190 loss:0.282\n",
      "########## 200 loss:0.254\n",
      "########## 210 loss:0.226\n",
      "########## 220 loss:0.194\n",
      "########## 230 loss:0.183\n",
      "########## 240 loss:0.171\n",
      "########## 250 loss:0.157\n",
      "########## 260 loss:0.145\n",
      "########## 270 loss:0.232\n",
      "########## 280 loss:0.226\n",
      "########## 290 loss:0.221\n",
      "########## 300 loss:0.207\n",
      "########## 310 loss:0.171\n",
      "########## 320 loss:0.152\n",
      "########## 330 loss:0.132\n",
      "########## 340 loss:0.123\n",
      "########## 350 loss:0.112\n",
      "########## 360 loss:0.126\n",
      "########## 370 loss:0.134\n",
      "########## 380 loss:0.109\n",
      "########## 390 loss:0.100\n",
      "########## 400 loss:0.092\n",
      "########## 410 loss:0.082\n",
      "########## 420 loss:0.081\n",
      "########## 430 loss:0.074\n",
      "########## 440 loss:0.073\n",
      "########## 450 loss:0.072\n",
      "########## 460 loss:0.078\n",
      "########## 470 loss:0.077\n",
      "########## 480 loss:0.077\n",
      "########## 490 loss:0.072\n",
      "########## 500 loss:0.070\n",
      "########## 510 loss:0.066\n",
      "########## 520 loss:0.066\n",
      "########## 530 loss:0.069\n",
      "########## 540 loss:0.062\n",
      "########## 550 loss:0.062\n",
      "########## 560 loss:0.057\n",
      "########## 570 loss:0.058\n",
      "########## 580 loss:0.054\n",
      "########## 590 loss:0.062\n",
      "########## 600 loss:0.064\n",
      "########## 610 loss:0.054\n",
      "########## 620 loss:0.053\n",
      "########## 630 loss:0.049\n",
      "########## 640 loss:0.056\n",
      "########## 650 loss:0.054\n",
      "########## 660 loss:0.054\n",
      "########## 670 loss:0.062\n",
      "########## 680 loss:0.068\n",
      "########## 690 loss:0.054\n",
      "########## 700 loss:0.046\n",
      "########## 710 loss:0.048\n",
      "########## 720 loss:0.044\n",
      "########## 730 loss:0.051\n",
      "########## 740 loss:0.054\n",
      "########## 750 loss:0.084\n",
      "########## 760 loss:0.287\n",
      "########## 770 loss:0.349\n",
      "########## 780 loss:0.199\n",
      "########## 790 loss:0.151\n",
      "########## 800 loss:0.120\n",
      "########## 810 loss:0.100\n",
      "########## 820 loss:0.086\n",
      "########## 830 loss:0.064\n",
      "########## 840 loss:0.055\n",
      "########## 850 loss:0.048\n",
      "########## 860 loss:0.046\n",
      "########## 870 loss:0.042\n",
      "########## 880 loss:0.040\n",
      "########## 890 loss:0.040\n",
      "########## 900 loss:0.039\n",
      "########## 910 loss:0.039\n",
      "########## 920 loss:0.039\n",
      "########## 930 loss:0.038\n",
      "########## 940 loss:0.041\n",
      "########## 950 loss:0.040\n",
      "########## 960 loss:0.039\n",
      "########## 970 loss:0.037\n",
      "########## 980 loss:0.035\n",
      "########## 990 loss:0.035\n",
      "########## 1000 loss:0.036\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t f_r -n cnn_gru -o cnn_gru_f_r_identifier_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Residual based f_r identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-GRU Model\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 10 loss:8.558\n",
      "########## 20 loss:1.130\n",
      "########## 30 loss:0.600\n",
      "########## 40 loss:0.474\n",
      "########## 50 loss:0.359\n",
      "########## 60 loss:0.370\n",
      "########## 70 loss:0.308\n",
      "########## 80 loss:0.289\n",
      "########## 90 loss:0.234\n",
      "########## 100 loss:0.228\n",
      "########## 110 loss:0.178\n",
      "########## 120 loss:0.171\n",
      "########## 130 loss:0.155\n",
      "########## 140 loss:0.135\n",
      "########## 150 loss:0.131\n",
      "########## 160 loss:0.110\n",
      "########## 170 loss:0.109\n",
      "########## 180 loss:0.098\n",
      "########## 190 loss:0.120\n",
      "########## 200 loss:0.138\n",
      "########## 210 loss:0.109\n",
      "########## 220 loss:0.105\n",
      "########## 230 loss:0.117\n",
      "########## 240 loss:0.103\n",
      "########## 250 loss:0.082\n",
      "########## 260 loss:0.066\n",
      "########## 270 loss:0.065\n",
      "########## 280 loss:0.077\n",
      "########## 290 loss:0.075\n",
      "########## 300 loss:0.074\n",
      "########## 310 loss:0.089\n",
      "########## 320 loss:0.089\n",
      "########## 330 loss:0.071\n",
      "########## 340 loss:0.088\n",
      "########## 350 loss:0.064\n",
      "########## 360 loss:0.058\n",
      "########## 370 loss:0.061\n",
      "########## 380 loss:0.061\n",
      "########## 390 loss:0.057\n",
      "########## 400 loss:0.054\n",
      "########## 410 loss:0.050\n",
      "########## 420 loss:0.043\n",
      "########## 430 loss:0.044\n",
      "########## 440 loss:0.048\n",
      "########## 450 loss:0.047\n",
      "########## 460 loss:0.058\n",
      "########## 470 loss:0.047\n",
      "########## 480 loss:0.043\n",
      "########## 490 loss:0.045\n",
      "########## 500 loss:0.062\n",
      "########## 510 loss:0.062\n",
      "########## 520 loss:0.079\n",
      "########## 530 loss:0.057\n",
      "########## 540 loss:0.041\n",
      "########## 550 loss:0.040\n",
      "########## 560 loss:0.041\n",
      "########## 570 loss:0.038\n",
      "########## 580 loss:0.038\n",
      "########## 590 loss:0.038\n",
      "########## 600 loss:0.044\n",
      "########## 610 loss:0.040\n",
      "########## 620 loss:0.046\n",
      "########## 630 loss:0.039\n",
      "########## 640 loss:0.124\n",
      "########## 650 loss:0.105\n",
      "########## 660 loss:0.068\n",
      "########## 670 loss:0.052\n",
      "########## 680 loss:0.043\n",
      "########## 690 loss:0.042\n",
      "########## 700 loss:0.038\n",
      "########## 710 loss:0.035\n",
      "########## 720 loss:0.031\n",
      "########## 730 loss:0.032\n",
      "########## 740 loss:0.031\n",
      "########## 750 loss:0.032\n",
      "########## 760 loss:0.034\n",
      "########## 770 loss:0.040\n",
      "########## 780 loss:0.034\n",
      "########## 790 loss:0.048\n",
      "########## 800 loss:0.052\n",
      "########## 810 loss:0.067\n",
      "########## 820 loss:0.067\n",
      "########## 830 loss:0.045\n",
      "########## 840 loss:0.033\n",
      "########## 850 loss:0.037\n",
      "########## 860 loss:0.032\n",
      "########## 870 loss:0.047\n",
      "########## 880 loss:0.032\n",
      "########## 890 loss:0.030\n",
      "########## 900 loss:0.028\n",
      "########## 910 loss:0.026\n",
      "########## 920 loss:0.027\n",
      "########## 930 loss:0.036\n",
      "########## 940 loss:0.040\n",
      "########## 950 loss:0.030\n",
      "########## 960 loss:0.028\n",
      "########## 970 loss:0.027\n",
      "########## 980 loss:0.024\n",
      "########## 990 loss:0.024\n",
      "########## 1000 loss:0.024\n"
     ]
    }
   ],
   "source": [
    "%run RO_diagnoser.py -d train -t f_r -n cnn_gru -o cnn_gru_f_r_identifier_res -r on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
